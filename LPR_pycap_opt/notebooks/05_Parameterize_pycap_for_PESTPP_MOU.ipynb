{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4aaab02-1a82-43b4-aad6-4e642fdfa27f",
   "metadata": {},
   "source": [
    "# Set up Pycap LPR to operate with PEST++ for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52223298-4643-4a71-b29c-14c1830b04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pyemu\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, platform\n",
    "from ipywidgets import interact\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output\n",
    "import plotly.express as px\n",
    "import folium\n",
    "from shapely.geometry import MultiPoint\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02e584-c9e4-4742-83c2-562c2aa06e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PyCap Run Name is what all your outputs will have as a name. \n",
    "pycap_run_name = \"LPR_Redux\"\n",
    "\n",
    "### we need to trigger whether to run MOU or not\n",
    "run_mou = False\n",
    "#### Base directory for runs\n",
    "parent_run_path = Path(\"../pycap_runs\")\n",
    "\n",
    "#### depletion potential calculations directory\n",
    "base_run_path = parent_run_path / \"pycap_base\"\n",
    "pest_path = parent_run_path / \"pycap_pest\"\n",
    "template_path = pest_path / \"pycap_mou_template\"\n",
    "\n",
    "# assume that if run_mou is false, it's already been run\n",
    "if run_mou:\n",
    "    if pest_path.exists():\n",
    "        shutil.rmtree(pest_path)\n",
    "    template_path.mkdir(parents=True)\n",
    "\n",
    "#### finally define the scripts directory\n",
    "script_path = Path(\"../scripts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864fdb7-d721-4740-80cd-f72039e2105d",
   "metadata": {},
   "source": [
    "# Parameterization for PEST++ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b87d00-22d3-450a-af12-df4493dc17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not template_path.exists():\n",
    "    template_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b852186-b3ec-46e0-a295-9ba49c624167",
   "metadata": {},
   "source": [
    "#### let's load up the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebc87e-131c-4a6c-b89f-74bfa5d39a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_run_path / f\"{pycap_run_name}.yml\", 'r') as ifp:\n",
    "        indat = yaml.safe_load(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e340b4e-03a4-49bb-983e-a4b124f36876",
   "metadata": {},
   "source": [
    "#### and now parameterize inputs to vary in optimization. This will only be pumping rates for now\n",
    "\n",
    "First we set up template (`TPL`) files that allow PEST++ to update model input values by name. We do this by reading in the input (`YML`) file and replacing numeric values with updated values being changed by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd61c68-5152-4efd-9159-fe2e80f856ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# well-by-well pumping rates\n",
    "well_keys = [i for i in indat.keys() if i.startswith('well_')]\n",
    "pending_wells = [i for i in well_keys if 'pending' in indat[i]['status']]\n",
    "\n",
    "pars = list()\n",
    "parvals = list()\n",
    "\n",
    "# then again for pumping rate Q\n",
    "for k in well_keys:\n",
    "    cpar = f'{k}__q'\n",
    "    pars.append(cpar)\n",
    "    parvals.append(indat[k]['Q'])\n",
    "    indat[k]['Q'] = f'~{cpar:^45}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7b321-54fb-4978-96d5-87cc1d88139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out tpl file\n",
    "with open(template_path / f\"{pycap_run_name}.yml.tpl\", 'w') as ofp:\n",
    "    ofp.write('ptf ~\\n')\n",
    "    documents = yaml.dump(indat, ofp, default_flow_style = False, sort_keys = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6532c15-ca7a-4241-89be-60d586f6cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame of parameters\n",
    "pars_df = pd.DataFrame(index = pars, data= {'parval1':parvals})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94f0c0-419a-4eee-8442-375b993718e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316abfa-e814-430c-a0ae-1565eebeb114",
   "metadata": {},
   "source": [
    "### Next we need to be able to read in model ouputs to PEST++\n",
    "Now we write an instruction file (`INS`) that can navigate model output and read it into PEST++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54982082-96d4-4790-9575-49ecb2819777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ins file and external forward run file\n",
    "# set base case depletion observations\n",
    "basedeplobs = [f\"{indat[k]['name']}:bdpl\" for k in indat.keys() if 'stream' in k]\n",
    "\n",
    "# get list of unique stream names used in the run\n",
    "unique_rivers = list(set([i.split(':')[0] for i in basedeplobs]))\n",
    "\n",
    "# add in the totals/sums of proposed/existing/combined depletions for each stream\n",
    "basedeplobs.extend([f'{i}:{j}:bdpl' for i in unique_rivers for j in ['total_proposed','total_existing','total_combined']])\n",
    "\n",
    "with open(template_path / 'basedeplobs.dat','w') as ofp:\n",
    "    [ofp.write(i + '\\n') for i in basedeplobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ab6ea-07b8-4b58-ad68-d85e047bb168",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedeplobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42fa32-c081-4977-be3b-3ade1d7fc461",
   "metadata": {},
   "source": [
    "### Now read in the base case observation values for depletion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf22cf-20b4-4432-ba0b-76591cc75894",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = pd.read_csv(base_run_path/\"output\" / f'{pycap_run_name}.table_report.base_stream_depletion.csv', index_col=0)\n",
    "# read in the observation names and make a DataFrame to keep the results in\n",
    "bdplobs = pd.read_csv(template_path/'basedeplobs.dat', header=None)\n",
    "bdplobs.columns =['obsname']\n",
    "bdplobs.index = bdplobs.obsname\n",
    "bdplobs['obs_values'] = np.nan\n",
    "\n",
    "# now map the actual output values to the DataFrame\n",
    "for cob in bdplobs.obsname:\n",
    "    riv,wel,_ = cob.split(':')\n",
    "    bdplobs.loc[cob, 'obs_values'] = base_data.loc[wel][riv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1d9d5-cd7e-4601-835c-0f1755d79a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdplobs.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168739d0-b3b8-4c0a-8284-b1f1b8378f06",
   "metadata": {},
   "source": [
    "### We can combine all the outputs into a single dataframe and make the instruction file we'll need to read in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65228136-0e5d-453c-80a6-0a8ec3b813c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdplobs['obs_values'].to_csv(template_path / 'allobs.out', sep = ' ', header=None)\n",
    "\n",
    "with open(template_path / 'allobs.out.ins', 'w') as ofp:\n",
    "    ofp.write('pif ~\\n')\n",
    "    [ofp.write(f'l1 w !{i}!\\n') for i in bdplobs.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7d568-b6c2-47de-8a23-f9be0083cb96",
   "metadata": {},
   "source": [
    "### Now we need to make a PEST control file to orchestrate everything. Luckily, `pyemu` makes this straightforward now that we have made the `tpl` and `ins` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e854c0-87ba-41ac-a6d6-c065377d43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(template_path)\n",
    "pst = pyemu.Pst.from_io_files(*pyemu.utils.parse_dir_for_io_files('.'))\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78430479-6cee-43f0-9107-b725f72a5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = pst.parameter_data\n",
    "obs = pst.observation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f628f1-ce3a-4049-a7d9-f8f391c82d82",
   "metadata": {},
   "source": [
    "# let's clean up some of the data and add important values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b85c1-d77d-49b9-9cda-4487a6ed2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name paramter groups according to the type of parameter\n",
    "pars.loc[pars.parnme.str.endswith(\"q\"), \"pargp\"] = \"pumping\"\n",
    "# set initial values\n",
    "pars.loc[pars_df.index,'parval1'] = pars_df.parval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c258c0-ae92-4852-b625-77623c77a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_pump = .2 #(as a fraction)\n",
    "# set upper and lower bounds on pumping rates as well - initially allow wells to go down to 0 or increase to 1.2x\n",
    "pars.loc[pars.pargp==\"pumping\",\"parlbnd\"] = 0 \n",
    "pars.loc[pars.pargp==\"pumping\", \"parubnd\"] = pars.loc[pars.pargp==\"pumping\", \"parval1\"]*(1+del_pump)\n",
    "pars.partrans = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684bb4a",
   "metadata": {},
   "source": [
    "### We need to make some definitions for multi-objective optimization algorithm (MOU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65d3df",
   "metadata": {},
   "source": [
    "### first, optionally, we can consider only the wells greater than a specified depletion potential threshold be managed.\n",
    "### Do this by setting the variable `dp_thresh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = gp.read_file(base_run_path / 'depletion_potential.json')\n",
    "dp.set_index('index', inplace=True)\n",
    "dp_thresh = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.loc[dp.Depletion_Potential>= dp_thresh].explore(column=\"Depletion_Potential\",\n",
    "                  vmin=0,vmax=1,\n",
    "                  style_kwds={\"style_function\":\n",
    "                                  lambda x: \n",
    "                                  {\"radius\":x[\"properties\"][\"Depletion_Potential\"]*15}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ef910",
   "metadata": {},
   "source": [
    "### now let's assign only the wells exceeding the depletion potential threshold to be adjustable (e.g. \"decision variables\" or \"decvars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars[\"wellname\"] = [i.split(\"__\")[0] for i in pars.index]\n",
    "pars.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33df69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.wellname.isin(dp.loc[dp.Depletion_Potential >= dp_thresh].index),'pargp'] = 'decvars'\n",
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b38fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to \"fix\" (e.g. make unadjustable) the pumping rates that are not decision variables\n",
    "pars.loc[pars.pargp==\"pumping\", \"partrans\"] = \"fixed\"\n",
    "pars.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1a415",
   "metadata": {},
   "source": [
    "### we need to sample a prior population of pumping rates, centered reasonably closely to the initial pumping rates. To do this, we assume we can temporarily set the upper and lower bounds to, say, +/1 10% of the initial value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.pargp==\"decvars\", \"parlbnd\"] = pars.loc[pars.pargp==\"decvars\", \"parval1\"]*0.8\n",
    "pars.loc[pars.pargp==\"decvars\", \"parubnd\"] = pars.loc[pars.pargp==\"decvars\", \"parval1\"]*1.2\n",
    "pars.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa836ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start with about 2x the number of decision variables as the population size\n",
    "num_reals = 170\n",
    "# sample decision variables from a uniform distribution\n",
    "dvpop = pyemu.ParameterEnsemble.from_uniform_draw(pst,num_reals=num_reals)\n",
    "\n",
    "# record to external file for PESTPP-MOU\n",
    "dvpop.to_csv(template_path / \"initial_dvpop.csv\")\n",
    "# tell PESTPP-MOU about the new file\n",
    "pst.pestpp_options[\"mou_dv_population_file\"] = 'initial_dvpop.csv'\n",
    "# reset the decision variable bounds\n",
    "pars['parlbnd'] = 0\n",
    "pars['parubnd'] = pars['parval1'] *(1+del_pump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5c380",
   "metadata": {},
   "source": [
    "### now we need to identify the (competing) objectives. This will be total pumping in all the decision variables and total depletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccabb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a prior information equation aggregating all the pumping int he decision variables\n",
    "pst.add_pi_equation(pars.loc[pars.pargp=='decvars','parnme'], # parameter names to include in the equation\n",
    "                    pilbl=\"obj_well\",  # the prior information equation name\n",
    "                    obs_group=\"greater_than_pumping\") # note the \"greater_\" prefix.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d774b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next identify the total depletion as a distinct observation group\n",
    "obs.loc[obs.index.str.contains(\"total_combined\"), \"obgnme\"] = \"less_than_depletion\"\n",
    "# now reset all weights except this one to be 0\n",
    "obs.weight = 0\n",
    "obs.loc[obs.obgnme==\"less_than_depletion\", \"weight\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"mou_objectives\"] = [\"obj_well\",\n",
    "                                        \"lpr:total_combined:bdpl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some additional PESTPP-MOU options:\n",
    "pst.pestpp_options[\"mou_population_size\"] = num_reals #twice the number of decision variables\n",
    "pst.pestpp_options[\"mou_save_population_every\"] = 1 # save lots of files! \n",
    "                                                    # but this way we can inspect how MOU progressed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad591886",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 50\n",
    "pst.model_command = ['python run_pycap_standalone_opt_mou.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccfb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(str(template_path / \"mou.pst\"), version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b11081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy over directories\n",
    "MASTER_path = pest_path / \"MASTER_mou\"\n",
    "if run_mou:\n",
    "\n",
    "    if MASTER_path.exists():\n",
    "        shutil.rmtree(MASTER_path)\n",
    "    # copy over the binaries into template first so they get distributed\n",
    "\n",
    "\n",
    "    #copy over the correct binary\n",
    "    if \"window\" in platform.platform().lower():\n",
    "        shutil.copy2('../../binaries/PESTPP/windows/pestpp-mou.exe', template_path / 'pestpp-mou.exe')\n",
    "    elif \"linux\" in platform.platform().lower():\n",
    "        shutil.copy2('../../binaries/PESTPP/linux/pestpp-mou', template_path / 'pestpp-mou')\n",
    "    elif \"mac\" in platform.platform().lower():\n",
    "        shutil.copy2('../../binaries/PESTPP/mac/pestpp-mou', template_path / 'pestpp-mou')\n",
    "\n",
    "    # we also need the forward run script\n",
    "    shutil.copy2(script_path / 'run_pycap_standalone_opt_mou.py', \n",
    "                template_path / 'run_pycap_standalone_opt_mou.py')\n",
    "\n",
    "    # and we need the base yml file\n",
    "    shutil.copy2(base_run_path / 'LPR_Redux.yml',\n",
    "                template_path / 'LPR_Redux.yml')\n",
    "\n",
    "    # finally populate the MASTER path with the template_path files\n",
    "    shutil.copytree(template_path, MASTER_path)\n",
    "    os.remove(MASTER_path / 'allobs.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_mou:\n",
    "    pyemu.os_utils.run(\"pestpp-mou mou.pst /e\",cwd=str(MASTER_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0c480",
   "metadata": {},
   "source": [
    "## now let's have a look at the results (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17257362",
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_df = pd.read_csv(MASTER_path / \"mou.pareto.archive.summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01aaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns to simpler names for plotting\n",
    "pareto_df = pareto_df.loc[pareto_df.apply(lambda x: x.nsga2_front==1 and x.is_feasible==1,axis=1),:].rename(\n",
    "    columns={\n",
    "        'lpr:total_combined:bdpl':'streamflow_obj',\n",
    "        'obj_well':'pumping_obj'\n",
    "    }\n",
    ")\n",
    "pareto_df.member = [str(i) for i in pareto_df.member]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pareto(currgen):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.scatter(pareto_df.streamflow_obj, pareto_df.pumping_obj, c='.5', marker='.', alpha=.4)\n",
    "    currdf = pareto_df.loc[pareto_df.generation==currgen]\n",
    "    ax.scatter(currdf.streamflow_obj, currdf.pumping_obj, c='b', marker='.')\n",
    "    ax.set_title(f'Pareto Tradeoff for Generation {currgen}')\n",
    "    ax.set_xlabel('streamflow_obj')\n",
    "    ax.set_ylabel('pumping_obj')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_pareto,  currgen=(0,50,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dbab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b20dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset decision variables to the realizations that are included in the pareto curve\n",
    "pareto_df_final = pareto_df.loc[pareto_df.generation==50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the decision variable pumping rates\n",
    "dv_df = pd.concat([pd.read_csv(i, index_col=0)\n",
    "                   for i in MASTER_path.glob(\"*dv_pop*\")])\n",
    "dv_df = pd.concat([dv_df, pd.read_csv(MASTER_path / 'initial_dvpop.csv', index_col=0)])\n",
    "dv_df.index = [str(i) for i in dv_df.index]\n",
    "dv_df = dv_df[~dv_df.index.duplicated(keep='first')]\n",
    "dv_df = dv_df.loc[pareto_df_final.member]\n",
    "dv_df.columns = [i.split(\"__\")[0] for i in dv_df.columns]\n",
    "dv_df = dv_df.T\n",
    "dv_df['geometry'] = dp.loc[dv_df.index, 'geometry']\n",
    "dv_df = gp.GeoDataFrame(data=dv_df, crs=dp.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d07508",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_df.index = [i.split('__')[0] for i in pars_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789125e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cc in dv_df.columns:\n",
    "    if 'geometry' not in cc:\n",
    "        dv_df[cc] /= pars_df.loc[dv_df.index,'parval1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__)\n",
    "\n",
    "@app.callback(\n",
    "    Output('scatter-plot', 'figure'),\n",
    "    Input('scatter-plot', 'clickData')\n",
    ")\n",
    "def update_scatter_highlight(clickData):\n",
    "    # Base scatter plot\n",
    "    fig = px.scatter(\n",
    "        pareto_df_final, x='streamflow_obj', y='pumping_obj', title=\"Pareto Tradeoff\"\n",
    "    )\n",
    "\n",
    "    # Highlight selected point\n",
    "    if clickData:\n",
    "        index = clickData['points'][0]['pointIndex']\n",
    "        fig.add_trace(\n",
    "            px.scatter(\n",
    "                pareto_df_final.iloc[[index]],  x='streamflow_obj', y='pumping_obj'\n",
    "            ).update_traces(\n",
    "                marker=dict(size=15, color='red', line=dict(width=2, color='black'))\n",
    "            ).data[0]\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        dcc.Graph(id='scatter-plot'),\n",
    "    ], style={'width': '50%', 'display': 'inline-block'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Iframe(id='map-plot', width='100%', height='600')\n",
    "    ], style={'width': '50%', 'display': 'inline-block'})\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('map-plot', 'srcDoc'),\n",
    "    Input('scatter-plot', 'clickData')\n",
    ")\n",
    "def display_map(clickData):\n",
    "    if clickData is None:\n",
    "        return \"\"\n",
    "\n",
    "    index = clickData['points'][0]['pointIndex']\n",
    "    \n",
    "    # Get the values from the selected column\n",
    "    val_array = dv_df.iloc[:, index].values\n",
    "    min_val, max_val = val_array.min(), val_array.max()\n",
    "    scaled_values = 3 + 12 * (val_array - min_val) / (max_val - min_val + 1e-6)  # avoid divide-by-zero\n",
    "    norm = mcolors.Normalize(vmin=min_val, vmax=max_val)\n",
    "    cmap = matplotlib.colormaps['magma']\n",
    "\n",
    "\n",
    "    geometries = dv_df[\"geometry\"]\n",
    "\n",
    "    points = list(zip(geometries, scaled_values,\n",
    "                      [\n",
    "                          mcolors.to_hex(cmap(norm(v))) for v in val_array\n",
    "                      ],\n",
    "                      val_array))   \n",
    "\n",
    "    if not points:\n",
    "        return \"\"\n",
    "\n",
    "    # Center map on centroid\n",
    "    centroid = MultiPoint([pt for pt, _, _,_  in points]).centroid\n",
    "    m = folium.Map(location=[centroid.y, centroid.x], zoom_start=11)\n",
    "\n",
    "    for pt, radius, ccolor, val in points:\n",
    "        folium.CircleMarker(\n",
    "            location=[pt.y, pt.x], weight=1, radius=radius/2,  # Adjust scaling as needed\n",
    "            color=ccolor, fill=True,  fill_color=ccolor, fill_opacity=0.7,\n",
    "            popup=f\"% pumping: {val:.2f}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    return m.get_root().render()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=4242)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb10910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ab7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycap",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
