{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4aaab02-1a82-43b4-aad6-4e642fdfa27f",
   "metadata": {},
   "source": [
    "# Set up Pycap LPR to operate with PEST++ for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52223298-4643-4a71-b29c-14c1830b04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pyemu\n",
    "import matplotlib.pyplot as plt\n",
    "import os, platform, shutil\n",
    "from pycap.analysis_project import Project\n",
    "from  datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02e584-c9e4-4742-83c2-562c2aa06e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Path to excel input file. Note can use absolute or relative path.\n",
    "pycap_inputs_excel = Path(\"../../PyCap/PyCap_USGS/pycap-dss2/Notebooks/Inputs/LPR_Prepped.xlsx\")\n",
    "\n",
    "#### PyCap Run Name is what all your outputs will have as a name. \n",
    "pycap_run_name = \"LPR_Redux\"\n",
    "\n",
    "#### Base directory for runs\n",
    "parent_run_path = Path(\"../pycap_runs\")\n",
    "\n",
    "#### depletion potential calculations directory\n",
    "\n",
    "base_run_path = parent_run_path / \"pycap_base\"\n",
    "pest_path = parent_run_path / \"pycap_pest\"\n",
    "template_path = pest_path / \"pycap_template\"\n",
    "if pest_path.exists():\n",
    "    shutil.rmtree(pest_path)\n",
    "template_path.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864fdb7-d721-4740-80cd-f72039e2105d",
   "metadata": {},
   "source": [
    "# Parameterization for PEST++ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b87d00-22d3-450a-af12-df4493dc17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not template_path.exists():\n",
    "    template_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b852186-b3ec-46e0-a295-9ba49c624167",
   "metadata": {},
   "source": [
    "#### let's load up the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebc87e-131c-4a6c-b89f-74bfa5d39a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_run_path / f\"{pycap_run_name}.yml\", 'r') as ifp:\n",
    "        indat = yaml.safe_load(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e340b4e-03a4-49bb-983e-a4b124f36876",
   "metadata": {},
   "source": [
    "#### and now parameterize inputs to vary in optimization, Monte Carlo, and other analyses\n",
    "\n",
    "First we set up template (`TPL`) files that allow PEST++ to update model input values by name. We do this by reading in the input (`YML`) file and replacing numeric values with updated values being changed by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffc126-e812-457f-b620-2e92f028344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global T and S\n",
    "T_init = indat['project_properties']['T']\n",
    "S_init = indat['project_properties']['S']\n",
    "\n",
    "indat['project_properties']['T'] = f'~{\"global_T\":^16s}~'\n",
    "indat['project_properties']['S'] = f'~{\"global_S\":^16s}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd61c68-5152-4efd-9159-fe2e80f856ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now well-by-well apportionment and pumping rates\n",
    "well_keys = [i for i in indat.keys() if i.startswith('well_')]\n",
    "app_keys = [[j for j in indat[i].keys() if j.startswith('stream_apportionment')]\n",
    "            for i in well_keys]\n",
    "pending_wells = [i for i in well_keys if 'pending' in indat[i]['status']]\n",
    "allkeys = dict(zip(well_keys, app_keys))\n",
    "\n",
    "pars = list()\n",
    "parvals = list()\n",
    "\n",
    "# for apportionment\n",
    "for k,v in allkeys.items():\n",
    "    for cv in v:\n",
    "        cpar = f'{k}__{cv}'\n",
    "        pars.append(cpar)\n",
    "        parvals.append(indat[k][cv]['apportionment'])\n",
    "        indat[k][cv]['apportionment'] = f'~{cpar:^45}~'\n",
    "# then again for pumping rate Q\n",
    "for k,v in allkeys.items():\n",
    "    cpar = f'{k}__q'\n",
    "    pars.append(cpar)\n",
    "    parvals.append(indat[k]['Q'])\n",
    "    indat[k]['Q'] = f'~{cpar:^45}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7b321-54fb-4978-96d5-87cc1d88139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out tpl file\n",
    "with open(template_path / f\"{pycap_run_name}.yml.tpl\", 'w') as ofp:\n",
    "    ofp.write('ptf ~\\n')\n",
    "    documents = yaml.dump(indat, ofp, default_flow_style = False, sort_keys = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6532c15-ca7a-4241-89be-60d586f6cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame of parameters\n",
    "pars_df = pd.DataFrame(index = pars, data= {'parval1':parvals})\n",
    "\n",
    "# add initial parameters to df\n",
    "pars_df = pd.concat([pars_df, pd.DataFrame(index = ['global_s','global_t'], data = {'parval1':[S_init,T_init]})])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94f0c0-419a-4eee-8442-375b993718e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316abfa-e814-430c-a0ae-1565eebeb114",
   "metadata": {},
   "source": [
    "### Next we need to be able to read in model ouputs to PEST++\n",
    "Now we write an instruction file (`INS`) that can navigate model output and read it into PEST++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54982082-96d4-4790-9575-49ecb2819777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ins file and external forward run file\n",
    "# set base case depletion observations\n",
    "basedeplobs = [f\"{indat[k]['name']}:bdpl\" for k in indat.keys() if 'stream' in k]\n",
    "\n",
    "# get list of unique stream names used in the run\n",
    "unique_rivers = list(set([i.split(':')[0] for i in basedeplobs]))\n",
    "\n",
    "# add in the totals/sums of proposed/existing/combined depletions for each stream\n",
    "basedeplobs.extend([f'{i}:{j}:bdpl' for i in unique_rivers for j in ['total_proposed','total_existing','total_combined']])\n",
    "\n",
    "with open(template_path / 'basedeplobs.dat','w') as ofp:\n",
    "    [ofp.write(i + '\\n') for i in basedeplobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ab6ea-07b8-4b58-ad68-d85e047bb168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basedeplobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0fa6e-3c0f-4029-b305-4c1d5f5075c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time-series\n",
    "# choose wells with individual time-series outputs.\n",
    "allstrmobs = [f\"{indat[k]['name']}\" for k in indat.keys() if \"stream\" in k]\n",
    "output_ts = allstrmobs \n",
    "\n",
    "# times you want to look at individual outputs, in this case just the depletions in the 5th year\n",
    "times = range(365*4,365*5+1) \n",
    "ts_obs = []\n",
    "for c_ts in output_ts:\n",
    "    ts_obs.extend([f'{c_ts}__{i}' for i in times])\n",
    "allobs = basedeplobs + ts_obs\n",
    "\n",
    "with open(template_path / 'ts_obs.dat' , 'w') as ofp:\n",
    "    [ofp.write(c_ts + '\\n') for c_ts in output_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42fa32-c081-4977-be3b-3ade1d7fc461",
   "metadata": {},
   "source": [
    "### Now read in the base case observation values for depletion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf22cf-20b4-4432-ba0b-76591cc75894",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = pd.read_csv(base_run_path/\"output\" / f'{pycap_run_name}.table_report.base_stream_depletion.csv', index_col=0)\n",
    "# read in the observation names and make a DataFrame to keep the results in\n",
    "bdplobs = pd.read_csv(template_path/'basedeplobs.dat', header=None)\n",
    "bdplobs.columns =['obsname']\n",
    "bdplobs.index = bdplobs.obsname\n",
    "bdplobs['obs_values'] = np.nan\n",
    "\n",
    "# now map the actual output values to the DataFrame\n",
    "for cob in bdplobs.obsname:\n",
    "    riv,wel,_ = cob.split(':')\n",
    "    bdplobs.loc[cob, 'obs_values'] = base_data.loc[wel][riv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1d9d5-cd7e-4601-835c-0f1755d79a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdplobs.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b74d8-fd32-4147-a739-ee1ea047e929",
   "metadata": {},
   "source": [
    "### Next for time series - read in the results for the 5th year only for each well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22b5a5-0c69-4985-b97f-17c7a047f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = pd.read_csv(base_run_path / \"output\" / f'{pycap_run_name}.table_report.all_ts.csv',index_col=0)\n",
    "ts_data.columns = ts_data.columns.str.split('__').str[-1]\n",
    "ts_path = template_path / 'ts_obs.dat' \n",
    "output_ts = [i.strip() for i in open(ts_path, 'r').readlines()]\n",
    "ts_df = pd.DataFrame(index= ts_obs,  data = {'obsname':ts_obs, 'obs_values':np.nan})\n",
    "for cob in ts_df.index:\n",
    "    criv,ctime=cob.split('__')\n",
    "    ts_df.loc[cob, 'obs_values'] = ts_data.loc[int(ctime)][criv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36a09f-495f-4f5a-9866-5eb482bbe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168739d0-b3b8-4c0a-8284-b1f1b8378f06",
   "metadata": {},
   "source": [
    "### We can combine all the outputs into a single dataframe and make the instruction file we'll need to read in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65228136-0e5d-453c-80a6-0a8ec3b813c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allout = pd.concat([bdplobs,ts_df])\n",
    "allout['obs_values'].to_csv(template_path / 'allobs.out', sep = ' ', header=None)\n",
    "\n",
    "with open(template_path / 'allobs.out.ins', 'w') as ofp:\n",
    "    ofp.write('pif ~\\n')\n",
    "    [ofp.write(f'l1 w !{i}!\\n') for i in allout.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7d568-b6c2-47de-8a23-f9be0083cb96",
   "metadata": {},
   "source": [
    "### Now we need to make a PEST control file to orchestrate everything. Luckily, `pyemu` makes this straightforward now that we have made the `tpl` and `ins` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e854c0-87ba-41ac-a6d6-c065377d43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(template_path)\n",
    "pst = pyemu.Pst.from_io_files(*pyemu.utils.parse_dir_for_io_files('.'))\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78430479-6cee-43f0-9107-b725f72a5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = pst.parameter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f628f1-ce3a-4049-a7d9-f8f391c82d82",
   "metadata": {},
   "source": [
    "# let's clean up some of the data and add important values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b85c1-d77d-49b9-9cda-4487a6ed2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name paramter groups according to the type of parameter\n",
    "pars.loc[pars.parnme.str.contains(\"global\"), \"pargp\"] = \"global\"\n",
    "pars.loc[pars.parnme.str.endswith(\"q\"), \"pargp\"] = \"pumping\"\n",
    "pars.loc[pars.parnme.str.contains(\"stream\"), \"pargp\"] = \"apportionment\"\n",
    "# set initial values\n",
    "pars.loc[pars_df.index,'parval1'] = pars_df.parval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c258c0-ae92-4852-b625-77623c77a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30868514-a1dd-411e-a942-9ba90f6bc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set apportionment changes\n",
    "# how much to change apportionment\n",
    "del_apport = 0.1\n",
    "\n",
    "# apport lower and upper bound\n",
    "#pars.loc[pars.index.str.startswith('well_'),'parlbnd'] = pars.loc[pars.index.str.startswith('well_'),'parval1']-.1\n",
    "pars.loc[pars.pargp==\"apportionment\", \"parlbnd\"] = pars.loc[pars.pargp==\"apportionment\", \"parval1\"] - del_apport\n",
    "pars.loc[pars.pargp==\"apportionment\", \"parubnd\"] = pars.loc[pars.pargp==\"apportionment\", \"parval1\"] + del_apport\n",
    "\n",
    "# force overall lowerbound and upperbound as defined in .xlsx inputs\n",
    "pars.loc[(pars.pargp=='apportionment')&\n",
    "    (pars.parlbnd < indat['project_properties']['Min_FracInt']),\n",
    "    'parlbnd'] = indat['project_properties']['Min_FracInt']\n",
    "pars.loc[(pars.pargp=='apportionment')&\n",
    "    (pars.parubnd > indat['project_properties']['Max_FracInt']),\n",
    "    'parubnd'] = indat['project_properties']['Max_FracInt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d4189-365a-4618-8f4a-e4b7c2911083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set lower and upper bounds for T and S as defined in .xlsx inputs\n",
    "pars.loc[(pars.pargp=='global_t'),'parlbnd'] = indat['project_properties']['Min_T']\n",
    "pars.loc[(pars.pargp=='global_t'),'parubnd'] = indat['project_properties']['Max_T']\n",
    "\n",
    "pars.loc[(pars.pargp=='global_s'),'parlbnd'] = indat['project_properties']['Min_S']\n",
    "pars.loc[(pars.pargp=='global_s'),'parubnd'] = indat['project_properties']['Max_S']\n",
    "\n",
    "# set transforms for all parameters to 'none', except for T which can be a log-transform\n",
    "pars.partrans = 'none'\n",
    "pars.loc['global_t','partrans']='log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb74b81-bb3d-499d-9c40-664f4448ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup and save pst file\n",
    "pst.control_data.noptmax = 0\n",
    "pst.model_command = [f'python run_pycap.py {pycap_run_name}.yml']\n",
    "pst.pestpp_options['par_sigma_range']=6\n",
    "pst.pestpp_options['ies_num_reals'] = 50\n",
    "\n",
    "pst.write(str(template_path / 'prior_mc.pst'), version=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a7404",
   "metadata": {},
   "source": [
    "### Now we'll make a couple directories.....one for NOPTMAX=0 and another as MASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy over dir\n",
    "nm0_path = pest_path / \"nm0\"\n",
    "if nm0_path.exists():\n",
    "    shutil.rmtree(nm0_path)\n",
    "MASTER_path = pest_path / \"MASTER\"\n",
    "if MASTER_path.exists():\n",
    "    shutil.rmtree(MASTER_path)\n",
    "\n",
    "for cdest in [nm0_path, MASTER_path]:\n",
    "    shutil.copytree(template_path, cdest)\n",
    "    os.remove(cdest / 'allobs.out')\n",
    "    # shutil.rmtree(cdest / 'output') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aaa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "PyCap_Path = os.path.join(current_dir, '..','pycap')\n",
    "\n",
    "shutil.copy2('run_pycap.py',template_dir/'run_pycap.py')\n",
    "shutil.copy2(yml_name, template_dir)\n",
    "\n",
    "if (template_dir/'pycap-dss').exists():\n",
    "    shutil.rmtree(template_dir/'pycap-dss'/'pycap')\n",
    "\n",
    "shutil.copytree(PyCap_Path, template_dir/'pycap-dss'/'pycap')\n",
    "\n",
    "if (template_dir/'output').exists():\n",
    "    shutil.rmtree(template_dir/'output')\n",
    "\n",
    "shutil.copytree(os.path.join(current_dir, 'output'), template_dir/'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147615d-4b0d-4d03-a91e-c4e782389ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "PyCap_Path = os.path.join(current_dir, '..','..','..','pycap-dss','pycap-dss','pycap')\n",
    "PyCap_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58297908-09b0-4442-adad-1e9190e31751",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47965a1-0bd7-4788-b90d-9931cdaf42f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac4436-1d45-4e48-8fd1-6ca846da6d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9737036-3448-439b-b9d4-5e14f39874bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MC\n",
    "run_global_sen = False\n",
    "run_global_sen_distrib = False\n",
    "run_ies = True\n",
    "\n",
    "\n",
    "if MonteCarlo == \"Y\":\n",
    "    SetupMC()\n",
    "\n",
    "    os.chdir(cwd)\n",
    "    if run_ies:\n",
    "        if 'window' in platform.platform().lower():\n",
    "            pestpp_ex = '../../dependencies/win_bin/pestpp-ies'\n",
    "        else:\n",
    "            pestpp_ex = '../../dependencies/mac_bin/pestpp-ies'\n",
    "        pyemu.os_utils.start_workers(\n",
    "                worker_dir=str(template_dir), \n",
    "                exe_rel_path=pestpp_ex,\n",
    "                pst_rel_path='prior_mc.pst', \n",
    "                num_workers=20,\n",
    "                worker_root='./', \n",
    "                master_dir='MASTER')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e97a5d-c8ca-47bf-9bcd-901e9c1c7ae7",
   "metadata": {},
   "source": [
    "# Post-processing Monte Carlo Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cacd38-dcc5-46de-8d38-44275c2fe2a0",
   "metadata": {},
   "source": [
    "#### Look at raw PHI histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee949d7-6bae-4dea-8cb4-0844f493ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.read_csv('./MASTER/prior_mc.0.obs.csv', index_col=0)\n",
    "obs.index = obs.index.astype(str)\n",
    "obs = obs.loc[reals_to_keep] \n",
    "ts_obs = obs[[i for i in obs.columns if not i.endswith(':bdpl')]]\n",
    "bdpl_obs = obs[[i for i in obs.columns if i.endswith(':bdpl')]]\n",
    "ts_lox = np.unique([i.split('__')[0] for i in ts_obs.columns])\n",
    "tmp2 = ts_obs.T.copy()\n",
    "tmp2['time'] = [int(i.split('__')[1]) for i in tmp2.index]\n",
    "tmp2['lox'] = [str(i.split('__')[0]) for i in tmp2.index]\n",
    "all_time_series = pd.read_csv('output/{}.table_report.all_ts.csv'.format(pycap_run_name), index_col=0)\n",
    "cum_depl = all_time_series.sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba8174-c6d6-4789-b7b2-90b483621c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_lox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed96d9-9c4c-4047-92dd-337f07c044b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MonteCarlo == \"Y\":\n",
    "    # check phi\n",
    "    phi = pd.read_csv('./MASTER/prior_mc.phi.actual.csv',index_col=0).T.iloc[5:]\n",
    "    phi_org = phi.copy()\n",
    "    phi.columns =['phi']\n",
    "    phi.hist(bins=50)\n",
    "\n",
    "    # only change if there are a very small number of extreme outliers\n",
    "    phitoohigh = 20000000\n",
    "    phi = phi.loc[phi.phi<phitoohigh]\n",
    "    phi.hist(bins=50)\n",
    "\n",
    "    reals_to_keep = phi.index\n",
    "    reject_reals = list(set(phi_org.index) - set(reals_to_keep)) # Keep rejected realizations in case we want to review them\n",
    "    print('Number of MC runs kept is ', len(reals_to_keep))\n",
    "\n",
    "    # read in all MC observations\n",
    "    # Note: Large file, takes a while to read in. \n",
    "    obs = pd.read_csv('./MASTER/prior_mc.0.obs.csv', index_col=0)\n",
    "    obs.index = obs.index.astype(str)\n",
    "\n",
    "    obs = obs.loc[reals_to_keep] \n",
    "\n",
    "    # parse into time-series\n",
    "    ts_obs = obs[[i for i in obs.columns if not i.endswith(':bdpl')]]\n",
    "    bdpl_obs = obs[[i for i in obs.columns if i.endswith(':bdpl')]]\n",
    "\n",
    "    ts_lox = np.unique([i.split('__')[0] for i in ts_obs.columns])\n",
    "    \n",
    "    tmp2 = ts_obs.T.copy()\n",
    "    tmp2['time'] = [int(i.split('__')[1]) for i in tmp2.index]\n",
    "    tmp2['lox'] = [str(i.split('__')[0]) for i in tmp2.index]\n",
    "\n",
    "    # look at timeseries outputs\n",
    "    all_time_series = pd.read_csv('output/{}.table_report.all_ts.csv'.format(pycap_run_name), index_col=0)\n",
    "    \n",
    "    # sum up cumulative depletions (NOTE: assumes only one stream used in MC)\n",
    "    cum_depl = all_time_series.sum(axis=1)\n",
    "\n",
    "    # plot up time-series depletions\n",
    "    fig,ax = plt.subplots(nrows=1, ncols=1)\n",
    "    ax.plot(all_time_series, alpha=0.6, c='k', lw=0.2)\n",
    "    ax.plot(cum_depl, c='r')\n",
    "    #fig.set_title('Cumulative Depl in all streams in Monte Carlo Analysis')\n",
    "    plt.savefig('output/cum_depl_MC_{}.png'.format(pycap_run_name))\n",
    "\n",
    "    # plot up each well's last year of depletion\n",
    "    fig,ax = plt.subplots(nrows=len(ts_lox), ncols=1, sharex=True, figsize=(10,4))\n",
    "    i=0\n",
    "                \n",
    "    for cts in ts_lox:\n",
    "        tmp = tmp2.loc[tmp2['lox']==cts]\n",
    "        tmp.set_index('time', drop = True, inplace=True)\n",
    "        tmp = tmp.drop('lox', axis=1)\n",
    "        ax =tmp.plot(alpha=0.4, c='k', lw=0.1, legend=None)\n",
    "        tmp['base'].plot(c='r')\n",
    "        ax.set_title(cts)\n",
    "        i+=1\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/individual_depl_MC_{}.png'.format(pycap_run_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10424c-31fe-432c-b569-c60609d16500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
